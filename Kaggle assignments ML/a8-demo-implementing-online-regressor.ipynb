{"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\" />\n    \n## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n\nAuthor: [Yury Kashnitskiy](https://yorko.github.io). Translated by [Sergey Oreshkov](https://www.linkedin.com/in/sergeoreshkov/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose.","metadata":{"_uuid":"e7b6d47fd0acfa7f50fb062aa0ea9c5e39d5702a"}},{"cell_type":"markdown","source":"# <center> Assignment #8 (demo)\n\n## <center> Implementation of online regressor","metadata":{"_uuid":"29bacf3cd638678716d8acd0aac384c802f580b2"}},{"cell_type":"markdown","source":"Here we'll implement a regressor trained with stochastic gradient descent (SGD). Fill in the missing code. If you do evething right, you'll pass a simple embedded test.","metadata":{"_uuid":"ab60e2f37db47b71f08414ea20a335bacb699fb5"}},{"cell_type":"markdown","source":"## <center>Linear regression and Stochastic Gradient Descent","metadata":{"_uuid":"004ac2081acafc7bb2c3b48bec97815be48e3256"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.base import BaseEstimator\nfrom sklearn.metrics import mean_squared_error, log_loss, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"a6b0bb1582f5593c7f02cd5219eaccb28758c9f0","execution":{"iopub.status.busy":"2021-11-26T16:23:31.875580Z","iopub.execute_input":"2021-11-26T16:23:31.876136Z","iopub.status.idle":"2021-11-26T16:23:32.926398Z","shell.execute_reply.started":"2021-11-26T16:23:31.876078Z","shell.execute_reply":"2021-11-26T16:23:32.925513Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Implement class `SGDRegressor`. Specification:\n- class is inherited from `sklearn.base.BaseEstimator`\n- constructor takes parameters `eta` – gradient step ($10^{-3}$ by default) and `n_epochs` – dataset pass count (3 by default)\n- constructor also creates `mse_` and `weights_` lists in order to track mean squared error and weight vector during gradient descent iterations\n- Class has `fit` and `predict` methods\n- The `fit` method takes matrix `X` and vector `y` (`numpy.array` objects) as parameters, appends column of ones to  `X` on the left side, initializes weight vector `w` with **zeros** and then makes `n_epochs` iterations of weight updates (you may refer to this [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237) for details), and for every iteration logs mean squared error and weight vector `w` in corresponding lists we created in the constructor. \n- Additionally the `fit` method will create `w_` variable to store weights which produce minimal mean squared error\n- The `fit` method returns current instance of the `SGDRegressor` class, i.e. `self`\n- The `predict` method takes `X` matrix, adds column of ones to the left side and returns prediction vector, using weight vector `w_`, created by the `fit` method.","metadata":{"_uuid":"4046185f0d664d32e72585d85bf929db97b87222"}},{"cell_type":"code","source":"class SGDRegressor(BaseEstimator):\n    \n    def __init__(self, eta=1e-3, n_epochs=3):\n        self.eta = eta\n        self.n_epochs = n_epochs\n        self.mse_ = []\n        self.weights_ = []\n        \n    def fit(self, X, y):\n        # add a column of ones to the left from X\n        X = np.hstack([np.ones([X.shape[0], 1]), X])\n        \n        # initialize w with zeros, (d + 1)-dimensional (2-dimensional)\n        w = np.zeros(X.shape[1])\n        \n        for it in tqdm(range(self.n_epochs)):\n            for i in range(X.shape[0]):\n                \n                # new_w is used for simultanious updates of w_0, w_1, ..., w_d\n                new_w = w.copy()\n                # special (simpler) formula for w_0\n                new_w[0] += self.eta * (y[i] - w.dot(X[i, :]))\n                for j in range(1, X.shape[1]):\n                    new_w[j] += self.eta * (y[i] - w.dot(X[i, :])) * X[i, j]  \n                w = new_w.copy()\n                \n                # store the current weight vector\n                self.weights_.append(w)\n                # store current loss function\n                self.mse_.append(mean_squared_error(y, X.dot(w)))\n        # the \"best\" vector of weights        \n        self.w_ = self.weights_[np.argmin(self.mse_)]\n                \n        return self\n                  \n    def predict(self, X):\n        # add a column of ones to the left from X\n        X = np.hstack([np.ones([X.shape[0], 1]), X])\n        # linear prediction\n        return X.dot(self.w_)                  ","metadata":{"_uuid":"70b6bac0390e590377c2c22562a006636eaa4cc4","execution":{"iopub.status.busy":"2021-11-26T16:23:40.069518Z","iopub.execute_input":"2021-11-26T16:23:40.069816Z","iopub.status.idle":"2021-11-26T16:23:40.077828Z","shell.execute_reply.started":"2021-11-26T16:23:40.069766Z","shell.execute_reply":"2021-11-26T16:23:40.076820Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Let's test out the algorithm on height/weight data. We will predict heights (in inches) based on weights (in lbs).","metadata":{"_uuid":"4e0bc1895989329650557bc8f469cb33f692d1a4"}},{"cell_type":"code","source":"data_demo = pd.read_csv('../input/weights_heights.csv')","metadata":{"_uuid":"4baa092f182db4ac4f2cc8d4557c5ed09a89b178","execution":{"iopub.status.busy":"2021-11-26T16:23:44.033683Z","iopub.execute_input":"2021-11-26T16:23:44.034165Z","iopub.status.idle":"2021-11-26T16:23:44.070317Z","shell.execute_reply.started":"2021-11-26T16:23:44.033926Z","shell.execute_reply":"2021-11-26T16:23:44.069599Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data_demo['Weight'], data_demo['Height']);\nplt.xlabel('Weight (lbs)')\nplt.ylabel('Height (Inch)')\nplt.grid();","metadata":{"_uuid":"4a1a3dacc860c74d2c39811e28af0d0cc69dd0ea","execution":{"iopub.status.busy":"2021-11-26T16:23:49.424488Z","iopub.execute_input":"2021-11-26T16:23:49.425085Z","iopub.status.idle":"2021-11-26T16:23:49.983520Z","shell.execute_reply.started":"2021-11-26T16:23:49.425030Z","shell.execute_reply":"2021-11-26T16:23:49.982679Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X, y = data_demo['Weight'].values, data_demo['Height'].values","metadata":{"_uuid":"760f39db3fd5efefe9e9e1b001b6df034f9575a7","execution":{"iopub.status.busy":"2021-11-26T16:23:57.208175Z","iopub.execute_input":"2021-11-26T16:23:57.208625Z","iopub.status.idle":"2021-11-26T16:23:57.212594Z","shell.execute_reply.started":"2021-11-26T16:23:57.208584Z","shell.execute_reply":"2021-11-26T16:23:57.211733Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Perform train/test split and scale data.","metadata":{"_uuid":"47bc57020935c57feadea43025d28adea20e31a7"}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                     test_size=0.3,\n                                                     random_state=17)","metadata":{"_uuid":"3908032cf11872f75c0794c89600f452d8ba1175","execution":{"iopub.status.busy":"2021-11-26T16:23:59.088696Z","iopub.execute_input":"2021-11-26T16:23:59.089188Z","iopub.status.idle":"2021-11-26T16:23:59.096209Z","shell.execute_reply.started":"2021-11-26T16:23:59.089122Z","shell.execute_reply":"2021-11-26T16:23:59.095526Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape([-1, 1]))\nX_valid_scaled = scaler.transform(X_valid.reshape([-1, 1]))","metadata":{"_uuid":"5c72768f019fa199027dfa60e50d979dafa90885","execution":{"iopub.status.busy":"2021-11-26T16:24:01.982672Z","iopub.execute_input":"2021-11-26T16:24:01.983269Z","iopub.status.idle":"2021-11-26T16:24:01.988375Z","shell.execute_reply.started":"2021-11-26T16:24:01.982906Z","shell.execute_reply":"2021-11-26T16:24:01.987585Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Train created `SGDRegressor` with `(X_train_scaled, y_train)` data. Leave default parameter values for now.","metadata":{"_uuid":"3dd1cfd5964170a4e916171a7906a88215831508"}},{"cell_type":"code","source":"\nsgd_reg = SGDRegressor()\nsgd_reg.fit(X_train_scaled, y_train)","metadata":{"_uuid":"01bb8e49a0499e48b5bee2c38fb9ffbd3247ff3e","execution":{"iopub.status.busy":"2021-11-26T16:24:34.338801Z","iopub.execute_input":"2021-11-26T16:24:34.339109Z","iopub.status.idle":"2021-11-26T16:24:55.113710Z","shell.execute_reply.started":"2021-11-26T16:24:34.339052Z","shell.execute_reply":"2021-11-26T16:24:55.112816Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Draw a chart with training process  – dependency of mean squared error from the i-th SGD iteration number.","metadata":{"_uuid":"b6ca9a0486cf1c89fd6edb70759a939353b857ef"}},{"cell_type":"code","source":"plt.plot(range(len(sgd_reg.mse_)), sgd_reg.mse_)\nplt.xlabel('updates')\nplt.ylabel('MSE');","metadata":{"_uuid":"ca8dd04db2eba86340308ba96e49d80dbb0f15df","execution":{"iopub.status.busy":"2021-11-26T16:26:17.997880Z","iopub.execute_input":"2021-11-26T16:26:17.998580Z","iopub.status.idle":"2021-11-26T16:26:18.247649Z","shell.execute_reply.started":"2021-11-26T16:26:17.998506Z","shell.execute_reply":"2021-11-26T16:26:18.246679Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Print the minimal value of mean squared error and the best weights vector.","metadata":{"_uuid":"1efe52d81eeec338817647a7c57f46a860f41d31"}},{"cell_type":"code","source":"np.min(sgd_reg.mse_), sgd_reg.w_","metadata":{"_uuid":"84808aab7acaf5fd49a92e5a1877163e97b94906","execution":{"iopub.status.busy":"2021-11-26T16:25:04.060204Z","iopub.execute_input":"2021-11-26T16:25:04.060688Z","iopub.status.idle":"2021-11-26T16:25:04.071620Z","shell.execute_reply.started":"2021-11-26T16:25:04.060641Z","shell.execute_reply":"2021-11-26T16:25:04.070640Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Draw chart of model weights ($w_0$ and $w_1$) behavior during training.","metadata":{"_uuid":"91bb34f2d42f87b7b352dfa38c07e233863154ce"}},{"cell_type":"code","source":"plt.subplot(121)\nplt.plot(range(len(sgd_reg.weights_)), \n         [w[0] for w in sgd_reg.weights_]);\nplt.subplot(122)\nplt.plot(range(len(sgd_reg.weights_)), \n         [w[1] for w in sgd_reg.weights_]);","metadata":{"_uuid":"b382dcaaaa8dffc4813e34cace68c63635f2dddb","execution":{"iopub.status.busy":"2021-11-26T16:25:06.362644Z","iopub.execute_input":"2021-11-26T16:25:06.363269Z","iopub.status.idle":"2021-11-26T16:25:06.793504Z","shell.execute_reply.started":"2021-11-26T16:25:06.363200Z","shell.execute_reply":"2021-11-26T16:25:06.792523Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Make a prediction for hold-out  set `(X_valid_scaled, y_valid)` and check MSE value.","metadata":{"_uuid":"c8bed1eb24256d97164ab396b02ad8fb0eabe069"}},{"cell_type":"code","source":"# you code here\nsgd_holdout_mse = mean_squared_error(y_valid, \n                                        sgd_reg.predict(X_valid_scaled))\nsgd_holdout_mse","metadata":{"_uuid":"61206ff5908cd4c9a04ce08c2caef6e81b3c204e","execution":{"iopub.status.busy":"2021-11-26T16:25:26.122496Z","iopub.execute_input":"2021-11-26T16:25:26.123042Z","iopub.status.idle":"2021-11-26T16:25:26.133604Z","shell.execute_reply.started":"2021-11-26T16:25:26.122994Z","shell.execute_reply":"2021-11-26T16:25:26.132485Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Do the same thing for `LinearRegression` class from `sklearn.linear_model`. Evaluate MSE for hold-out set.","metadata":{"_uuid":"1b4450206464e151b40f32443c90716f7527740b"}},{"cell_type":"code","source":"# you code here\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression().fit(X_train_scaled, y_train)\nprint(lm.coef_, lm.intercept_)\nlinreg_holdout_mse = mean_squared_error(y_valid, \n                                        lm.predict(X_valid_scaled))\nlinreg_holdout_mse","metadata":{"scrolled":true,"_uuid":"9af850fa4a66d596df7143abec65eaf06264f477","execution":{"iopub.status.busy":"2021-11-26T16:25:36.045154Z","iopub.execute_input":"2021-11-26T16:25:36.045489Z","iopub.status.idle":"2021-11-26T16:25:36.258587Z","shell.execute_reply.started":"2021-11-26T16:25:36.045442Z","shell.execute_reply":"2021-11-26T16:25:36.258011Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"try:\n    assert (sgd_holdout_mse - linreg_holdout_mse) < 1e-4\n    print('Correct!')\nexcept AssertionError:\n    print(\"Something's not good.\\n Linreg's holdout MSE: {}\"\n          \"\\n SGD's holdout MSE: {}\".format(linreg_holdout_mse, \n                                            sgd_holdout_mse))","metadata":{"_uuid":"61e4706c45d87b09d6e9ea03a7bd8ac6eae3ee17","execution":{"iopub.status.busy":"2021-11-26T16:25:43.725432Z","iopub.execute_input":"2021-11-26T16:25:43.726005Z","iopub.status.idle":"2021-11-26T16:25:43.731615Z","shell.execute_reply.started":"2021-11-26T16:25:43.725951Z","shell.execute_reply":"2021-11-26T16:25:43.730727Z"},"trusted":true},"execution_count":16,"outputs":[]}]}